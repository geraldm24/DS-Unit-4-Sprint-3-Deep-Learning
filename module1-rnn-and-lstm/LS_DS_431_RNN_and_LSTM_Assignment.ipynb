{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Copy of LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0Uw54ml5z7z",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwN24wPXACxI",
        "colab_type": "code",
        "outputId": "72874226-1192-49c0-d1f4-2df08e21168c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkG3O_X2szj2",
        "colab_type": "code",
        "outputId": "6eb54337-b070-40bd-dd64-f80ccc14a279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "import os\n",
        "from tensorflow import distribute, config, tpu\n",
        "resolver = distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "config.experimental_connect_to_cluster(resolver)\n",
        "tpu.experimental.initialize_tpu_system(resolver)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.97.60.242:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.97.60.242:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.tpu.topology.Topology at 0x7f05aa24a2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ltj1je1fp5rO",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "with requests.get(url) as res:\n",
        "    res.encoding = 'utf-8'\n",
        "    works = res.text\n",
        "\n",
        "# Remove the ebook header\n",
        "works = works[2907:]\n",
        "\n",
        "# Remove carriage return char\n",
        "works = works.replace('\\r', ' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVqGx9FBeq9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "pattern = re.compile(r\"(.*)(\\*\\sCONTENT\\sNOTE\\s\\(added in 2017\\)\\s\\*.*)\", \n",
        "                     flags=re.DOTALL)\n",
        "matches = pattern.search(works)\n",
        "works = matches.group(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEFwxBQ367LB",
        "colab_type": "code",
        "outputId": "1fec6f27-a088-4afc-f2e1-305f7334509c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import sys\n",
        "\n",
        "size = str(round(sys.getsizeof(works) / 1000000, 2)) + ' MB'\n",
        "size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'11.43 MB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfpOg0Gd_HjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "chars = list(set(works))\n",
        "\n",
        "char_int = {c:i for i, c in enumerate(chars)}\n",
        "int_char = {i:c for i, c in enumerate(chars)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BazsKnYFStkE",
        "colab_type": "code",
        "outputId": "3a85066d-a742-4e65-8be7-afc6a523fbc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "MAXLEN = 40\n",
        "STEP = 5\n",
        "\n",
        "encoded = [char_int[c] for c in works]\n",
        "\n",
        "sequences = [] # 40 chars long\n",
        "next_char = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - MAXLEN, STEP):\n",
        "\n",
        "    sequences.append(encoded[i:i+MAXLEN])\n",
        "    next_char.append(encoded[i+MAXLEN])\n",
        "\n",
        "print(\"Sequences:\", len(sequences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequences: 1143122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGEBN-zr7rYM",
        "colab_type": "code",
        "outputId": "dc0090a5-872e-44de-a2ef-681b8a8ebcf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "print(len(encoded))\n",
        "print(sequences[0])\n",
        "print(next_char[0])\n",
        "print(sequences[1])\n",
        "print(next_char[1])\n",
        "print(sequences[2])\n",
        "print(next_char[2])\n",
        "print(\"works/step\", (len(works)-41)/5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5715646\n",
            "[52, 9, 84, 99, 100, 81, 51, 51, 84, 52, 100, 99, 72, 99, 72, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 63, 99, 72, 99, 72]\n",
            "37\n",
            "[81, 51, 51, 84, 52, 100, 99, 72, 99, 72, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 63, 99, 72, 99, 72, 37, 13, 8, 49, 99]\n",
            "97\n",
            "[100, 99, 72, 99, 72, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 63, 99, 72, 99, 72, 37, 13, 8, 49, 99, 97, 76, 77, 13, 95]\n",
            "57\n",
            "works/step 1143121.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9-TYv21T_4i",
        "colab_type": "code",
        "outputId": "ec1a1e02-0c07-4c13-919f-975bef14fb4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "print(\"encoded\", encoded[:10])\n",
        "print(\">>>>>>>>>> len(encoded)\", len(encoded))\n",
        "print(\"sequences\", sequences[0])\n",
        "print(\">>>>>>>>>> len(sequences[0])\", len(sequences[0]))\n",
        "print(\"next_char\", next_char[:10])\n",
        "print(\">>>>>>>>>> len(next_char)\", len(next_char))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoded [52, 9, 84, 99, 100, 81, 51, 51, 84, 52]\n",
            ">>>>>>>>>> len(encoded) 5715646\n",
            "sequences [52, 9, 84, 99, 100, 81, 51, 51, 84, 52, 100, 99, 72, 99, 72, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 63, 99, 72, 99, 72]\n",
            ">>>>>>>>>> len(sequences[0]) 40\n",
            "next_char [37, 97, 57, 95, 95, 99, 13, 71, 95, 61]\n",
            ">>>>>>>>>> len(next_char) 1143122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_8raBUEWMJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "# X and y \n",
        "\n",
        "X = np.zeros((len(sequences), MAXLEN, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        X[i,t,char] = 1\n",
        "\n",
        "    y[i, next_char[i]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JijS6JRLah1N",
        "colab_type": "code",
        "outputId": "2bb6b739-2540-4c95-8f4e-a17b6e94e7bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1143122, 40, 101), (1143122, 101))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbNYm7UjxTaK",
        "colab_type": "code",
        "outputId": "9bd4f70e-05a3-4e1e-b0c6-f061621a6fb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "X[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       ...,\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False,  True, False],\n",
              "       [False, False, False, ..., False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5btYOAUbj75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model\n",
        "strategy = distribute.experimental.TPUStrategy(resolver)\n",
        "with strategy.scope():\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.LSTM(128, input_shape=(MAXLEN, len(chars))),\n",
        "        keras.layers.Dense(len(chars), activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRRFQoeEdtqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "\n",
        "\n",
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(works) - MAXLEN - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = works[start_index: start_index + MAXLEN]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, MAXLEN, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGD0r4veekqs",
        "colab_type": "code",
        "outputId": "09101326-c49e-42b7-b41a-e4b11ee06d22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# fit\n",
        "model.fit(X, y,\n",
        "          batch_size=32,\n",
        "          epochs=15,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1147363 samples\n",
            "Epoch 1/15\n",
            "1147360/1147363 [============================>.] - ETA: 0s - loss: 1.6319\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"trius. \n",
            " \n",
            "LYSANDER. \n",
            "Be not afraid; she \"\n",
            "trius. \n",
            " \n",
            "LYSANDER. \n",
            "Be not afraid; she that is a preate. \n",
            "    VoNless, timows to you most treak’d Greals, fas, \n",
            "I’ll is the his Had \n",
            "      sule and centle mishame if that bein gent; \n",
            "    kight at to grack of minlow speak, \n",
            "’Ttwill I swike fight, and cally much away. \n",
            " fears hoth, yeb this pape. And I kive had frage his fear! \n",
            "O offly King leanes, Maicing his precey \n",
            "That’s his peranot, of my there to a poor, \n",
            "He die not bear on the sau\n",
            "1147363/1147363 [==============================] - 177s 155us/sample - loss: 1.6319\n",
            "Epoch 2/15\n",
            "1147072/1147363 [============================>.] - ETA: 0s - loss: 1.5408\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"provokes me to ridiculous \n",
            "    smiling. \"\n",
            "provokes me to ridiculous \n",
            "    smiling. \n",
            " \n",
            "SIR TOBY. \n",
            "You fill! \n",
            "  PEMPLIA. And, stay he, fall birther, somech? \n",
            " \n",
            "AENELLA. \n",
            "Like timm, no  whose, Sich a kince arroning or \n",
            "Strips, the cape lith read you and blocks. \n",
            "  CORIOLANUS. Ay, I have no coud of this. \n",
            "    If my Pornio! What are a choe that to \n",
            "    under, thy ours every. \n",
            "    One ladge of all, anget in on the facous. \n",
            " \n",
            "LACTRIUS. \n",
            "Let Reventuul was the ship will. \n",
            " \n",
            "DERVID \n",
            "To mi\n",
            "1147363/1147363 [==============================] - 177s 154us/sample - loss: 1.5408\n",
            "Epoch 3/15\n",
            "1147328/1147363 [============================>.] - ETA: 0s - loss: 1.4918\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"\n",
            "In Pompey’s Porch: for now, this fearfu\"\n",
            "\n",
            "In Pompey’s Porch: for now, this fearful. \n",
            " \n",
            "IAGO. \n",
            "Hask be ouchscitions \n",
            "In carsuer play-like adars— \n",
            "Stands through. \n",
            " \n",
            "AUTIGEN. \n",
            "To an! that is in these, you af read age \n",
            "Blusples just. And I shall fears in year, \n",
            "Which his denelors, therefore this horle, \n",
            "For day thoughn till is my accite mons. \n",
            "  ANTONY. For, so fear by your life, \n",
            "    I las mine ambant 'twas rash for exack, \n",
            "Mider grooms shall abong neing of man. I slawn in mer, \n",
            "1147363/1147363 [==============================] - 178s 155us/sample - loss: 1.4918\n",
            "Epoch 4/15\n",
            "1147136/1147363 [============================>.] - ETA: 0s - loss: 1.4601\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"ave, \n",
            "As thou report’st thyself, wast th\"\n",
            "ave, \n",
            "As thou report’st thyself, wast that those beplitstate. \n",
            " \n",
            " Enter Percees, and comfort. \n",
            " \n",
            "      Enter JOHN. \n",
            " \n",
            "  Lieskning; O air love. For Jow, my reose: \n",
            "    Wherein a slave with frow! our muldle latter, \n",
            "And his for the gied quicked.             Exguit POL. \n",
            " Entil Propitish as in: \n",
            "Falish the sundry done queen cort end on town \n",
            "      tellower more thou a hended my lord. I'll \n",
            " trod the very comials my come, gencen no eor doon\n",
            "1147363/1147363 [==============================] - 178s 155us/sample - loss: 1.4601\n",
            "Epoch 5/15\n",
            "1147360/1147363 [============================>.] - ETA: 0s - loss: 1.4364\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"k Master Slender's purse? \n",
            "  SLENDER. Ay\"\n",
            "k Master Slender's purse? \n",
            "  SLENDER. Ay, we day what he rage, \n",
            "Deeding their trainety here apprayon. \n",
            "The pointed of he, hence intermonance, \n",
            "Scite troupour of her weather. \n",
            "  CAIURDERMARTANE. No feece, Mastersu, the than in \n",
            "speak best of truel, unmuck. \n",
            "  FIRST EDIE. I trot's blooked for you, not did, ladam, \n",
            "The mercy that haspity comembiant with \n",
            "    some. \n",
            " \n",
            "AGAMEMNON. \n",
            "Open to teriust stors nop, there is what you to tempress’d, a\n",
            "1147363/1147363 [==============================] - 177s 155us/sample - loss: 1.4364\n",
            "Epoch 6/15\n",
            "1147136/1147363 [============================>.] - ETA: 0s - loss: 1.4184\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \" would think \n",
            "    me an hypocrite indeed\"\n",
            " would think \n",
            "    me an hypocrite indeed; un; belong me upon Capitor. \n",
            " \n",
            "OCHEST. \n",
            "Mac' truly out a lighter'd indee. \n",
            "  SECOND MURDERER. O have not scall me and replay'd adricy. Ay's entice, dickly, \n",
            "          , wonching thing: thy little times \n",
            "    Was the birn the beach on his chapped see. \n",
            "  EPESSIO. Al ne’er held ’er cansing weacting to mine by \n",
            "Amperute were with state, out of I knockly, \n",
            "    Most crister os this taughty? \n",
            "  CAGE. P\n",
            "1147363/1147363 [==============================] - 178s 155us/sample - loss: 1.4184\n",
            "Epoch 7/15\n",
            "1147136/1147363 [============================>.] - ETA: 0s - loss: 1.4045\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \"nt; death, dearth, \n",
            "dissolutions of anci\"\n",
            "nt; death, dearth, \n",
            "dissolutions of ancinger were dalf monnige \n",
            "like the King amonge I as cousins a wort \n",
            "    Fore, bard but fool away. \n",
            "  WACKETHILEN. Lettingurius, stayone in mich \n",
            "    Not, I ceind a coup and misides revil \n",
            "    To what very too you nque doth six; they go here ill shall speaks \n",
            "                                                                                            Exeunt alone Was lord. Well, for here, good \n",
            "      \n",
            "1147363/1147363 [==============================] - 178s 155us/sample - loss: 1.4045\n",
            "Epoch 8/15\n",
            "1147296/1147363 [============================>.] - ETA: 0s - loss: 1.3928\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \"rt, \n",
            "Give ’t me again. Poor lady, she’ll\"\n",
            "rt, \n",
            "Give ’t me again. Poor lady, she’ll now know \n",
            "To a plain on an haste and partly is how? \n",
            "    Mean Advine fie, liest hours of a kind \n",
            "Buls’s have left me I smile-get his heaven: ’The should not yet \n",
            "That he will are whip? \n",
            " \n",
            "CKETEL. \n",
            "Good murday thy face to be trous. \n",
            " \n",
            " [_Exeuntub._] \n",
            " \n",
            "SCENE VIIIK. ] KING and LENUME \n",
            " \n",
            "  PHARMIAL. \n",
            "Why, beputier Grawis, you sit bethings of thine, but because \n",
            "The onness suppis’d troth, me now his \n",
            "1147363/1147363 [==============================] - 178s 156us/sample - loss: 1.3927\n",
            "Epoch 9/15\n",
            "1147200/1147363 [============================>.] - ETA: 0s - loss: 1.3830\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"loit, \n",
            "    For want of means, poor rats,\"\n",
            "loit, \n",
            "    For want of means, poor rats, whoe a kind. \n",
            " \n",
            "EMILIA. \n",
            "[_Aside._] ever, all the stands his house what, if \n",
            "Die those pursion, will know ese doth how the Daughters, \n",
            "let’le! Romeans I do not teal young Lapso, my lord he love chance. \n",
            "                                          [PragentT] \n",
            "    Cancif the hope thought the great enough; \n",
            "    Where's made with her beguar'd on the cause; \n",
            "    Queen This if enswer-by unshape intaned h\n",
            "1147363/1147363 [==============================] - 177s 155us/sample - loss: 1.3830\n",
            "Epoch 10/15\n",
            "1147232/1147363 [============================>.] - ETA: 0s - loss: 1.3736\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \"orious pirate, \n",
            "    A man of Claudio's y\"\n",
            "orious pirate, \n",
            "    A man of Claudio's your lord's tear'st; \n",
            "    But ow now fothing am, what with flere \n",
            "    mazried) to this hands, that if thou art \n",
            "but Hene. \n",
            " \n",
            "CLORD. \n",
            "He that lays' cause his rilds need of your matter. \n",
            "    Well, Marcush wrooners, we must, my lord, \n",
            "      PANDARBESS OF BESHERDER-OF CLEOPATRAHRE A puilVacts present in the Castee. That ler him? \n",
            " \n",
            "SELIN. SORDY FOLD And yet saft befoll bare John strong common \n",
            "    To m\n",
            "1147363/1147363 [==============================] - 179s 156us/sample - loss: 1.3736\n",
            "Epoch 11/15\n",
            "1147072/1147363 [============================>.] - ETA: 0s - loss: 1.3684\n",
            "----- Generating text after Epoch: 10\n",
            "----- Generating with seed: \"r \n",
            "Never to part with it, and here he st\"\n",
            "r \n",
            "Never to part with it, and here he stofficip, content, \n",
            "Are authore by tongue \n",
            "To kind that Shall his man reason, enter's man; \n",
            "    Which as en'ren's multicly, not, and am oppine of man than it you doe, \n",
            "    And though thus, the innothat Cupition, \n",
            "And, who thou pend sadstand, in this death \n",
            "    Sect earless with my law Here! For a man \n",
            "    Wy know the me! I would buirch your face \n",
            "    gitter to the discovernd my bringle hour \n",
            "Never \n",
            "1147363/1147363 [==============================] - 178s 155us/sample - loss: 1.3685\n",
            "Epoch 12/15\n",
            "1147104/1147363 [============================>.] - ETA: 0s - loss: 1.3622\n",
            "----- Generating text after Epoch: 11\n",
            "----- Generating with seed: \"endure for thee!            Exeunt \n",
            " \n",
            "SC\"\n",
            "endure for thee!            Exeunt \n",
            " \n",
            "SCENE IV. The done. \n",
            " \n",
            "                 Enter HYRSSAN \n",
            " \n",
            "    No, those dull'd needs, and fight more, and he were to cleed; \n",
            "  [To KOTHORUS]  For the anum een; I will I do? I ren \n",
            "      dream \n",
            "Cune of such as I did prevell here. The office on \n",
            "    That stool my true; he loves his won, \n",
            "    All being ladies nor a jointes ’tis \n",
            "voutaches with the enement. \n",
            " \n",
            "MERCUTIO. \n",
            "I know \n",
            "The need I about thy tud’\n",
            "1147363/1147363 [==============================] - 177s 154us/sample - loss: 1.3622\n",
            "Epoch 13/15\n",
            "1147328/1147363 [============================>.] - ETA: 0s - loss: 1.3563\n",
            "----- Generating text after Epoch: 12\n",
            "----- Generating with seed: \"n \n",
            "Full of rose-water and bestrew’d with\"\n",
            "n \n",
            "Full of rose-water and bestrew’d with my \n",
            "dewith. \n",
            " \n",
            " [_Kneelies of the else came._] \n",
            " \n",
            "TYBARDO. \n",
            "Good then, for the know adain’d martiful word \n",
            "I’ll take a hundred mother more. You love the sore \n",
            "Hath a biar he may to mine Mistress in thence, \n",
            "Our lords to me be well receive o'te puty, \n",
            "  sing frommand comfortor: and you tomow, \n",
            "    His dastly, but sense by harsh burgrity known. \n",
            "    Let me been to Rome from these treber sones: \n",
            "Whi\n",
            "1147363/1147363 [==============================] - 177s 155us/sample - loss: 1.3563\n",
            "Epoch 14/15\n",
            "1147072/1147363 [============================>.] - ETA: 0s - loss: 1.3514\n",
            "----- Generating text after Epoch: 13\n",
            "----- Generating with seed: \"Reads] 'First of the king: what shall of\"\n",
            "Reads] 'First of the king: what shall of you enjoy it well, \n",
            "    for the wind at vickine that they never \n",
            "Wears where, My lields, Same thee. \n",
            "And the way still one thoughts Yornigence; \n",
            "    And possessed no pacefur, widness most of \n",
            "  assiusition'd of those; \n",
            "    And the good lives thus precegot them for I \n",
            "    To loose it notes to live of they wouching mad: \n",
            "Hath leave this pay themselfed with Attands, \n",
            "    The shall not a same noble w\n",
            "1147363/1147363 [==============================] - 178s 155us/sample - loss: 1.3514\n",
            "Epoch 15/15\n",
            "1147328/1147363 [============================>.] - ETA: 0s - loss: 1.3469\n",
            "----- Generating text after Epoch: 14\n",
            "----- Generating with seed: \"eave to love my head. \n",
            " \n",
            "ANTIOCHUS. \n",
            "[_A\"\n",
            "eave to love my head. \n",
            " \n",
            "ANTIOCHUS. \n",
            "[_Aside._] Good honourish neights men, our gentlemonster \n",
            "The protest action Kather, and gentle criece and France, \n",
            "Seyt of my nasking? No one, why, shemen them, \n",
            "Hath make hose ot my lift. \n",
            "In her, but I have make one of the crevinls \n",
            "Stand to thy pittard for my mocked best we? \n",
            " \n",
            "HECTOUS. \n",
            "To waited nextly happy this, trybe-bre stoed \n",
            "Why the pocks what had redrem’d with it. \n",
            " \n",
            "DEMETRIUS. \n",
            "Of Palda\n",
            "1147363/1147363 [==============================] - 178s 156us/sample - loss: 1.3469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fce420c95f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoVwZYFzq2ek",
        "colab_type": "code",
        "outputId": "f5122080-7bad-4ca7-a4f0-f91f3bdad6d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "1147404 % 8"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}